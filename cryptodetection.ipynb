{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880a0b4a-5269-4ec3-86fe-27ae930928cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 18:12:54.421306: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-13 18:12:54.599990: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-13 18:12:54.600232: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-13 18:12:54.653646: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-13 18:12:54.829972: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-13 18:12:56.307031: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "352d244e-c63c-4c99-8e60-0ca21c105520",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "normal = pd.read_csv(\"final-normal-data-set.csv\", nrows=1000)\n",
    "anormal = pd.read_csv(\"final-anormal-data-set.csv\", nrows=1000)\n",
    "\n",
    "#inserting column for result \n",
    "normal.insert(82, 'result', 0)\n",
    "anormal.insert(82, 'result', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95f0a527-0737-4553-bf87-fd85c5234917",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#combining datasets\n",
    "frames = [normal, anormal]\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f09649dc-4107-431f-b749-a665b550354d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425 examples in training, 575 examples for testing.\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(dataset, test_ratio=0.30):\n",
    "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]\n",
    "\n",
    "\n",
    "train_ds_pd, test_ds_pd = split_dataset(df)\n",
    "print(\"{} examples in training, {} examples for testing.\".format(\n",
    "    len(train_ds_pd), len(test_ds_pd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cdee38c-6a98-479a-8e91-504e83338948",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label = \"result\"\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fca1ee96-5771-40af-832e-4c02f8b44627",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 16 thread(s) for training\n",
      "Use /tmp/tmpe16g9moa as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'cpu_guest': <tf.Tensor 'data:0' shape=(None,) dtype=float64>, 'cpu_guest_nice': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'cpu_idle': <tf.Tensor 'data_2:0' shape=(None,) dtype=float64>, 'cpu_iowait': <tf.Tensor 'data_3:0' shape=(None,) dtype=float64>, 'cpu_irq': <tf.Tensor 'data_4:0' shape=(None,) dtype=float64>, 'cpu_nice': <tf.Tensor 'data_5:0' shape=(None,) dtype=float64>, 'cpu_softirq': <tf.Tensor 'data_6:0' shape=(None,) dtype=float64>, 'cpu_steal': <tf.Tensor 'data_7:0' shape=(None,) dtype=float64>, 'cpu_system': <tf.Tensor 'data_8:0' shape=(None,) dtype=float64>, 'cpu_total': <tf.Tensor 'data_9:0' shape=(None,) dtype=float64>, 'cpu_user': <tf.Tensor 'data_10:0' shape=(None,) dtype=float64>, 'diskio_sda1_disk_name': <tf.Tensor 'data_11:0' shape=(None,) dtype=string>, 'diskio_sda1_key': <tf.Tensor 'data_12:0' shape=(None,) dtype=string>, 'diskio_sda1_read_bytes': <tf.Tensor 'data_13:0' shape=(None,) dtype=int64>, 'diskio_sda1_time_since_update': <tf.Tensor 'data_14:0' shape=(None,) dtype=float64>, 'diskio_sda1_write_bytes': <tf.Tensor 'data_15:0' shape=(None,) dtype=int64>, 'diskio_sda_disk_name': <tf.Tensor 'data_16:0' shape=(None,) dtype=string>, 'diskio_sda_key': <tf.Tensor 'data_17:0' shape=(None,) dtype=string>, 'diskio_sda_read_bytes': <tf.Tensor 'data_18:0' shape=(None,) dtype=int64>, 'diskio_sda_time_since_update': <tf.Tensor 'data_19:0' shape=(None,) dtype=float64>, 'diskio_sda_write_bytes': <tf.Tensor 'data_20:0' shape=(None,) dtype=int64>, 'fs_/_device_name': <tf.Tensor 'data_21:0' shape=(None,) dtype=string>, 'fs_/_free': <tf.Tensor 'data_22:0' shape=(None,) dtype=int64>, 'fs_/_fs_type': <tf.Tensor 'data_23:0' shape=(None,) dtype=string>, 'fs_/_key': <tf.Tensor 'data_24:0' shape=(None,) dtype=string>, 'fs_/_mnt_point': <tf.Tensor 'data_25:0' shape=(None,) dtype=string>, 'fs_/_percent': <tf.Tensor 'data_26:0' shape=(None,) dtype=float64>, 'fs_/_size': <tf.Tensor 'data_27:0' shape=(None,) dtype=int64>, 'fs_/_used': <tf.Tensor 'data_28:0' shape=(None,) dtype=int64>, 'load_cpucore': <tf.Tensor 'data_29:0' shape=(None,) dtype=int64>, 'load_min1': <tf.Tensor 'data_30:0' shape=(None,) dtype=float64>, 'load_min15': <tf.Tensor 'data_31:0' shape=(None,) dtype=float64>, 'load_min5': <tf.Tensor 'data_32:0' shape=(None,) dtype=float64>, 'mem_active': <tf.Tensor 'data_33:0' shape=(None,) dtype=int64>, 'mem_available': <tf.Tensor 'data_34:0' shape=(None,) dtype=int64>, 'mem_buffers': <tf.Tensor 'data_35:0' shape=(None,) dtype=float64>, 'mem_cached': <tf.Tensor 'data_36:0' shape=(None,) dtype=int64>, 'mem_free': <tf.Tensor 'data_37:0' shape=(None,) dtype=int64>, 'mem_inactive': <tf.Tensor 'data_38:0' shape=(None,) dtype=int64>, 'mem_percent': <tf.Tensor 'data_39:0' shape=(None,) dtype=float64>, 'mem_shared': <tf.Tensor 'data_40:0' shape=(None,) dtype=int64>, 'mem_total': <tf.Tensor 'data_41:0' shape=(None,) dtype=float64>, 'mem_used': <tf.Tensor 'data_42:0' shape=(None,) dtype=int64>, 'memswap_free': <tf.Tensor 'data_43:0' shape=(None,) dtype=int64>, 'memswap_percent': <tf.Tensor 'data_44:0' shape=(None,) dtype=float64>, 'memswap_sin': <tf.Tensor 'data_45:0' shape=(None,) dtype=int64>, 'memswap_sout': <tf.Tensor 'data_46:0' shape=(None,) dtype=int64>, 'memswap_total': <tf.Tensor 'data_47:0' shape=(None,) dtype=int64>, 'memswap_used': <tf.Tensor 'data_48:0' shape=(None,) dtype=int64>, 'network_lo_cumulative_cx': <tf.Tensor 'data_49:0' shape=(None,) dtype=float64>, 'network_lo_cumulative_rx': <tf.Tensor 'data_50:0' shape=(None,) dtype=float64>, 'network_lo_cumulative_tx': <tf.Tensor 'data_51:0' shape=(None,) dtype=float64>, 'network_lo_cx': <tf.Tensor 'data_52:0' shape=(None,) dtype=float64>, 'network_lo_interface_name': <tf.Tensor 'data_53:0' shape=(None,) dtype=string>, 'network_lo_key': <tf.Tensor 'data_54:0' shape=(None,) dtype=string>, 'network_lo_rx': <tf.Tensor 'data_55:0' shape=(None,) dtype=float64>, 'network_lo_time_since_update': <tf.Tensor 'data_56:0' shape=(None,) dtype=float64>, 'network_lo_tx': <tf.Tensor 'data_57:0' shape=(None,) dtype=float64>, 'percpu_0_cpu_number': <tf.Tensor 'data_58:0' shape=(None,) dtype=int64>, 'percpu_0_guest': <tf.Tensor 'data_59:0' shape=(None,) dtype=float64>, 'percpu_0_guest_nice': <tf.Tensor 'data_60:0' shape=(None,) dtype=float64>, 'percpu_0_idle': <tf.Tensor 'data_61:0' shape=(None,) dtype=float64>, 'percpu_0_iowait': <tf.Tensor 'data_62:0' shape=(None,) dtype=float64>, 'percpu_0_irq': <tf.Tensor 'data_63:0' shape=(None,) dtype=float64>, 'percpu_0_key': <tf.Tensor 'data_64:0' shape=(None,) dtype=string>, 'percpu_0_nice': <tf.Tensor 'data_65:0' shape=(None,) dtype=float64>, 'percpu_0_softirq': <tf.Tensor 'data_66:0' shape=(None,) dtype=float64>, 'percpu_0_steal': <tf.Tensor 'data_67:0' shape=(None,) dtype=float64>, 'percpu_0_system': <tf.Tensor 'data_68:0' shape=(None,) dtype=float64>, 'percpu_0_total': <tf.Tensor 'data_69:0' shape=(None,) dtype=float64>, 'percpu_0_user': <tf.Tensor 'data_70:0' shape=(None,) dtype=float64>, 'processcount_running': <tf.Tensor 'data_71:0' shape=(None,) dtype=float64>, 'processcount_sleeping': <tf.Tensor 'data_72:0' shape=(None,) dtype=float64>, 'processcount_thread': <tf.Tensor 'data_73:0' shape=(None,) dtype=float64>, 'processcount_total': <tf.Tensor 'data_74:0' shape=(None,) dtype=float64>, 'system_hostname': <tf.Tensor 'data_75:0' shape=(None,) dtype=string>, 'system_hr_name': <tf.Tensor 'data_76:0' shape=(None,) dtype=string>, 'system_linux_distro': <tf.Tensor 'data_77:0' shape=(None,) dtype=string>, 'system_os_name': <tf.Tensor 'data_78:0' shape=(None,) dtype=string>, 'system_os_version': <tf.Tensor 'data_79:0' shape=(None,) dtype=string>, 'system_platform': <tf.Tensor 'data_80:0' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'data_81:0' shape=(None,) dtype=string>}\n",
      "Label: Tensor(\"data_82:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'cpu_guest': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'cpu_guest_nice': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'cpu_idle': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'cpu_iowait': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'cpu_irq': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'cpu_nice': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>), 'cpu_softirq': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_6:0' shape=(None,) dtype=float32>), 'cpu_steal': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_7:0' shape=(None,) dtype=float32>), 'cpu_system': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_8:0' shape=(None,) dtype=float32>), 'cpu_total': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_9:0' shape=(None,) dtype=float32>), 'cpu_user': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_10:0' shape=(None,) dtype=float32>), 'diskio_sda1_disk_name': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_11:0' shape=(None,) dtype=string>), 'diskio_sda1_key': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_12:0' shape=(None,) dtype=string>), 'diskio_sda1_read_bytes': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_11:0' shape=(None,) dtype=float32>), 'diskio_sda1_time_since_update': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_12:0' shape=(None,) dtype=float32>), 'diskio_sda1_write_bytes': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_13:0' shape=(None,) dtype=float32>), 'diskio_sda_disk_name': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_16:0' shape=(None,) dtype=string>), 'diskio_sda_key': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_17:0' shape=(None,) dtype=string>), 'diskio_sda_read_bytes': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_14:0' shape=(None,) dtype=float32>), 'diskio_sda_time_since_update': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_15:0' shape=(None,) dtype=float32>), 'diskio_sda_write_bytes': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_16:0' shape=(None,) dtype=float32>), 'fs_/_device_name': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_21:0' shape=(None,) dtype=string>), 'fs_/_free': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_17:0' shape=(None,) dtype=float32>), 'fs_/_fs_type': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_23:0' shape=(None,) dtype=string>), 'fs_/_key': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_24:0' shape=(None,) dtype=string>), 'fs_/_mnt_point': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_25:0' shape=(None,) dtype=string>), 'fs_/_percent': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_18:0' shape=(None,) dtype=float32>), 'fs_/_size': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_19:0' shape=(None,) dtype=float32>), 'fs_/_used': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_20:0' shape=(None,) dtype=float32>), 'load_cpucore': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_21:0' shape=(None,) dtype=float32>), 'load_min1': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_22:0' shape=(None,) dtype=float32>), 'load_min15': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_23:0' shape=(None,) dtype=float32>), 'load_min5': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_24:0' shape=(None,) dtype=float32>), 'mem_active': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_25:0' shape=(None,) dtype=float32>), 'mem_available': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_26:0' shape=(None,) dtype=float32>), 'mem_buffers': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_27:0' shape=(None,) dtype=float32>), 'mem_cached': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_28:0' shape=(None,) dtype=float32>), 'mem_free': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_29:0' shape=(None,) dtype=float32>), 'mem_inactive': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_30:0' shape=(None,) dtype=float32>), 'mem_percent': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_31:0' shape=(None,) dtype=float32>), 'mem_shared': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_32:0' shape=(None,) dtype=float32>), 'mem_total': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_33:0' shape=(None,) dtype=float32>), 'mem_used': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_34:0' shape=(None,) dtype=float32>), 'memswap_free': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_35:0' shape=(None,) dtype=float32>), 'memswap_percent': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_36:0' shape=(None,) dtype=float32>), 'memswap_sin': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_37:0' shape=(None,) dtype=float32>), 'memswap_sout': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_38:0' shape=(None,) dtype=float32>), 'memswap_total': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_39:0' shape=(None,) dtype=float32>), 'memswap_used': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_40:0' shape=(None,) dtype=float32>), 'network_lo_cumulative_cx': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_41:0' shape=(None,) dtype=float32>), 'network_lo_cumulative_rx': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_42:0' shape=(None,) dtype=float32>), 'network_lo_cumulative_tx': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_43:0' shape=(None,) dtype=float32>), 'network_lo_cx': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_44:0' shape=(None,) dtype=float32>), 'network_lo_interface_name': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_53:0' shape=(None,) dtype=string>), 'network_lo_key': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_54:0' shape=(None,) dtype=string>), 'network_lo_rx': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_45:0' shape=(None,) dtype=float32>), 'network_lo_time_since_update': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_46:0' shape=(None,) dtype=float32>), 'network_lo_tx': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_47:0' shape=(None,) dtype=float32>), 'percpu_0_cpu_number': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_48:0' shape=(None,) dtype=float32>), 'percpu_0_guest': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_49:0' shape=(None,) dtype=float32>), 'percpu_0_guest_nice': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_50:0' shape=(None,) dtype=float32>), 'percpu_0_idle': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_51:0' shape=(None,) dtype=float32>), 'percpu_0_iowait': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_52:0' shape=(None,) dtype=float32>), 'percpu_0_irq': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_53:0' shape=(None,) dtype=float32>), 'percpu_0_key': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_64:0' shape=(None,) dtype=string>), 'percpu_0_nice': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_54:0' shape=(None,) dtype=float32>), 'percpu_0_softirq': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_55:0' shape=(None,) dtype=float32>), 'percpu_0_steal': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_56:0' shape=(None,) dtype=float32>), 'percpu_0_system': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_57:0' shape=(None,) dtype=float32>), 'percpu_0_total': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_58:0' shape=(None,) dtype=float32>), 'percpu_0_user': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_59:0' shape=(None,) dtype=float32>), 'processcount_running': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_60:0' shape=(None,) dtype=float32>), 'processcount_sleeping': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_61:0' shape=(None,) dtype=float32>), 'processcount_thread': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_62:0' shape=(None,) dtype=float32>), 'processcount_total': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_63:0' shape=(None,) dtype=float32>), 'system_hostname': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_75:0' shape=(None,) dtype=string>), 'system_hr_name': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_76:0' shape=(None,) dtype=string>), 'system_linux_distro': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_77:0' shape=(None,) dtype=string>), 'system_os_name': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_78:0' shape=(None,) dtype=string>), 'system_os_version': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_79:0' shape=(None,) dtype=string>), 'system_platform': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_80:0' shape=(None,) dtype=string>), 'timestamp': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_81:0' shape=(None,) dtype=string>)}\n",
      "Training dataset read in 0:00:01.033816. Found 1425 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-02-13 18:31:23.2457 PST kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-02-13 18:31:23.2458 PST kernel.cc:772] Collect training examples\n",
      "[INFO 24-02-13 18:31:23.2458 PST kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-02-13 18:31:23.2461 PST kernel.cc:391] Number of batches: 2\n",
      "[INFO 24-02-13 18:31:23.2461 PST kernel.cc:392] Number of examples: 1425\n",
      "[INFO 24-02-13 18:31:23.2496 PST data_spec_inference.cc:305] 1417 item(s) have been pruned (i.e. they are considered out of dictionary) for the column timestamp (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "[INFO 24-02-13 18:31:23.2510 PST kernel.cc:792] Training dataset:\n",
      "Number of records: 1425\n",
      "Number of columns: 83\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 64 (77.1084%)\n",
      "\tCATEGORICAL: 19 (22.8916%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 64 (77.1084%)\n",
      "\t1: \"cpu_guest\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t2: \"cpu_guest_nice\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t3: \"cpu_idle\" NUMERICAL mean:7.93789 min:0 max:92.6 sd:25.045\n",
      "\t4: \"cpu_iowait\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t5: \"cpu_irq\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t6: \"cpu_nice\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t7: \"cpu_softirq\" NUMERICAL mean:0.0913684 min:0 max:3 sd:0.324858\n",
      "\t8: \"cpu_steal\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t9: \"cpu_system\" NUMERICAL mean:3.46828 min:0 max:20.2 sd:2.41124\n",
      "\t10: \"cpu_total\" NUMERICAL mean:92.1764 min:8.3 max:100 sd:24.8214\n",
      "\t11: \"cpu_user\" NUMERICAL mean:56.4452 min:4.5 max:97.2 sd:33.7717\n",
      "\t14: \"diskio_sda1_read_bytes\" NUMERICAL mean:11.4975 min:0 max:16384 sd:433.87\n",
      "\t15: \"diskio_sda1_time_since_update\" NUMERICAL mean:1.19162 min:0.6527 max:1.83636 sd:0.194092\n",
      "\t16: \"diskio_sda1_write_bytes\" NUMERICAL mean:38447.8 min:0 max:1.8432e+06 sd:177316\n",
      "\t19: \"diskio_sda_read_bytes\" NUMERICAL mean:63604.4 min:0 max:1.92266e+07 sd:781968\n",
      "\t20: \"diskio_sda_time_since_update\" NUMERICAL mean:1.19162 min:0.6527 max:1.83636 sd:0.194092\n",
      "\t21: \"diskio_sda_write_bytes\" NUMERICAL mean:96703.3 min:0 max:3.47341e+07 sd:1.11529e+06\n",
      "\t23: \"fs_/_free\" NUMERICAL mean:2.94819e+09 min:1.454e+08 max:5.6818e+09 sd:2.76028e+09\n",
      "\t27: \"fs_/_percent\" NUMERICAL mean:71.5761 min:47 max:96.9 sd:24.8129\n",
      "\t28: \"fs_/_size\" NUMERICAL mean:7.74867e+09 min:4.70811e+09 max:1.07259e+10 sd:3.00872e+09\n",
      "\t29: \"fs_/_used\" NUMERICAL mean:4.80048e+09 min:4.50614e+09 max:5.05082e+09 sd:2.48539e+08\n",
      "\t30: \"load_cpucore\" NUMERICAL mean:1 min:1 max:1 sd:0\n",
      "\t31: \"load_min1\" NUMERICAL mean:2.85598 min:1.28 max:5.12 sd:0.973379\n",
      "\t32: \"load_min15\" NUMERICAL mean:1.5183 min:0.47 max:2.78 sd:0.639621\n",
      "\t33: \"load_min5\" NUMERICAL mean:2.39771 min:1.11 max:3.66 sd:0.811241\n",
      "\t34: \"mem_active\" NUMERICAL mean:9.93524e+08 min:2.18792e+08 max:1.98511e+09 sd:6.31916e+08\n",
      "\t35: \"mem_available\" NUMERICAL mean:1.81406e+09 min:3.80551e+08 max:3.1047e+09 sd:9.19834e+08\n",
      "\t36: \"mem_buffers\" NUMERICAL mean:806705 min:0 max:2.15859e+06 sd:1.02309e+06\n",
      "\t37: \"mem_cached\" NUMERICAL mean:1.32747e+09 min:3.61665e+08 max:2.20035e+09 sd:8.80674e+08\n",
      "\t38: \"mem_free\" NUMERICAL mean:1.81406e+09 min:3.80551e+08 max:3.1047e+09 sd:9.19834e+08\n",
      "\t39: \"mem_inactive\" NUMERICAL mean:6.0938e+08 min:2.40943e+08 max:9.43505e+08 sd:3.37801e+08\n",
      "\t40: \"mem_percent\" NUMERICAL mean:51.9072 min:16.3 max:90.4 sd:25.5369\n",
      "\t41: \"mem_shared\" NUMERICAL mean:9.03033e+06 min:8.99891e+06 max:9.07264e+06 sd:10363.5\n",
      "\t42: \"mem_total\" NUMERICAL mean:3.84012e+09 min:3.70942e+09 max:3.9736e+09 sd:1.32086e+08\n",
      "\t43: \"mem_used\" NUMERICAL mean:2.02606e+09 min:6.04713e+08 max:3.59305e+09 sd:1.04759e+09\n",
      "\t44: \"memswap_free\" NUMERICAL mean:3.1956e+08 min:0 max:6.45919e+08 sd:3.22941e+08\n",
      "\t45: \"memswap_percent\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t46: \"memswap_sin\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t47: \"memswap_sout\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t48: \"memswap_total\" NUMERICAL mean:3.1956e+08 min:0 max:6.45919e+08 sd:3.22941e+08\n",
      "\t49: \"memswap_used\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t50: \"network_lo_cumulative_cx\" NUMERICAL mean:8340.11 min:400 max:21016 sd:7897.53\n",
      "\t51: \"network_lo_cumulative_rx\" NUMERICAL mean:4170.05 min:200 max:10508 sd:3948.77\n",
      "\t52: \"network_lo_cumulative_tx\" NUMERICAL mean:4170.05 min:200 max:10508 sd:3948.77\n",
      "\t53: \"network_lo_cx\" NUMERICAL mean:6.60772 min:0 max:288 sd:42.9769\n",
      "\t56: \"network_lo_rx\" NUMERICAL mean:3.30386 min:0 max:144 sd:21.4884\n",
      "\t57: \"network_lo_time_since_update\" NUMERICAL mean:1.19166 min:0.69546 max:1.83385 sd:0.193596\n",
      "\t58: \"network_lo_tx\" NUMERICAL mean:3.30386 min:0 max:144 sd:21.4884\n",
      "\t59: \"percpu_0_cpu_number\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t60: \"percpu_0_guest\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t61: \"percpu_0_guest_nice\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t62: \"percpu_0_idle\" NUMERICAL mean:7.81432 min:0 max:91.7 sd:24.8026\n",
      "\t63: \"percpu_0_iowait\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t64: \"percpu_0_irq\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t66: \"percpu_0_nice\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t67: \"percpu_0_softirq\" NUMERICAL mean:0.0940351 min:0 max:3 sd:0.335334\n",
      "\t68: \"percpu_0_steal\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t69: \"percpu_0_system\" NUMERICAL mean:3.50519 min:0 max:22 sd:2.42426\n",
      "\t70: \"percpu_0_total\" NUMERICAL mean:92.1857 min:8.3 max:100 sd:24.8026\n",
      "\t71: \"percpu_0_user\" NUMERICAL mean:56.7955 min:4.5 max:97.1 sd:33.7031\n",
      "\t72: \"processcount_running\" NUMERICAL mean:2.18807 min:1 max:5 sd:0.521534\n",
      "\t73: \"processcount_sleeping\" NUMERICAL mean:112.406 min:106 max:122 sd:3.66142\n",
      "\t74: \"processcount_thread\" NUMERICAL mean:161.539 min:138 max:211 sd:23.6564\n",
      "\t75: \"processcount_total\" NUMERICAL mean:114.594 min:109 max:124 sd:3.50296\n",
      "\n",
      "CATEGORICAL: 19 (22.8916%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\t12: \"diskio_sda1_disk_name\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"sda1\" 1425 (100%)\n",
      "\t13: \"diskio_sda1_key\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"disk_name\" 1425 (100%)\n",
      "\t17: \"diskio_sda_disk_name\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"sda\" 1425 (100%)\n",
      "\t18: \"diskio_sda_key\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"disk_name\" 1425 (100%)\n",
      "\t22: \"fs_/_device_name\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"/dev/sda1\" 720 (50.5263%)\n",
      "\t24: \"fs_/_fs_type\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"xfs\" 1425 (100%)\n",
      "\t25: \"fs_/_key\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"mnt_point\" 1425 (100%)\n",
      "\t26: \"fs_/_mnt_point\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"/\" 1425 (100%)\n",
      "\t54: \"network_lo_interface_name\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"lo\" 1425 (100%)\n",
      "\t55: \"network_lo_key\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"interface_name\" 1425 (100%)\n",
      "\t65: \"percpu_0_key\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"cpu_number\" 1425 (100%)\n",
      "\t76: \"system_hostname\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"vm1-graph-analytics\" 720 (50.5263%)\n",
      "\t77: \"system_hr_name\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"CentOS Linux 7.7.1908 64bit\" 1425 (100%)\n",
      "\t78: \"system_linux_distro\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"CentOS Linux 7.7.1908\" 1425 (100%)\n",
      "\t79: \"system_os_name\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"Linux\" 1425 (100%)\n",
      "\t80: \"system_os_version\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"3.10.0-1062.12.1.el7.x86_64\" 1425 (100%)\n",
      "\t81: \"system_platform\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"64bit\" 1425 (100%)\n",
      "\t82: \"timestamp\" CATEGORICAL has-dict vocab-size:1 num-oods:1425 (100%)\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-02-13 18:31:23.2512 PST kernel.cc:808] Configure learner\n",
      "[INFO 24-02-13 18:31:23.2514 PST kernel.cc:822] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^cpu_guest$\"\n",
      "features: \"^cpu_guest_nice$\"\n",
      "features: \"^cpu_idle$\"\n",
      "features: \"^cpu_iowait$\"\n",
      "features: \"^cpu_irq$\"\n",
      "features: \"^cpu_nice$\"\n",
      "features: \"^cpu_softirq$\"\n",
      "features: \"^cpu_steal$\"\n",
      "features: \"^cpu_system$\"\n",
      "features: \"^cpu_total$\"\n",
      "features: \"^cpu_user$\"\n",
      "features: \"^diskio_sda1_disk_name$\"\n",
      "features: \"^diskio_sda1_key$\"\n",
      "features: \"^diskio_sda1_read_bytes$\"\n",
      "features: \"^diskio_sda1_time_since_update$\"\n",
      "features: \"^diskio_sda1_write_bytes$\"\n",
      "features: \"^diskio_sda_disk_name$\"\n",
      "features: \"^diskio_sda_key$\"\n",
      "features: \"^diskio_sda_read_bytes$\"\n",
      "features: \"^diskio_sda_time_since_update$\"\n",
      "features: \"^diskio_sda_write_bytes$\"\n",
      "features: \"^fs_/_device_name$\"\n",
      "features: \"^fs_/_free$\"\n",
      "features: \"^fs_/_fs_type$\"\n",
      "features: \"^fs_/_key$\"\n",
      "features: \"^fs_/_mnt_point$\"\n",
      "features: \"^fs_/_percent$\"\n",
      "features: \"^fs_/_size$\"\n",
      "features: \"^fs_/_used$\"\n",
      "features: \"^load_cpucore$\"\n",
      "features: \"^load_min1$\"\n",
      "features: \"^load_min15$\"\n",
      "features: \"^load_min5$\"\n",
      "features: \"^mem_active$\"\n",
      "features: \"^mem_available$\"\n",
      "features: \"^mem_buffers$\"\n",
      "features: \"^mem_cached$\"\n",
      "features: \"^mem_free$\"\n",
      "features: \"^mem_inactive$\"\n",
      "features: \"^mem_percent$\"\n",
      "features: \"^mem_shared$\"\n",
      "features: \"^mem_total$\"\n",
      "features: \"^mem_used$\"\n",
      "features: \"^memswap_free$\"\n",
      "features: \"^memswap_percent$\"\n",
      "features: \"^memswap_sin$\"\n",
      "features: \"^memswap_sout$\"\n",
      "features: \"^memswap_total$\"\n",
      "features: \"^memswap_used$\"\n",
      "features: \"^network_lo_cumulative_cx$\"\n",
      "features: \"^network_lo_cumulative_rx$\"\n",
      "features: \"^network_lo_cumulative_tx$\"\n",
      "features: \"^network_lo_cx$\"\n",
      "features: \"^network_lo_interface_name$\"\n",
      "features: \"^network_lo_key$\"\n",
      "features: \"^network_lo_rx$\"\n",
      "features: \"^network_lo_time_since_update$\"\n",
      "features: \"^network_lo_tx$\"\n",
      "features: \"^percpu_0_cpu_number$\"\n",
      "features: \"^percpu_0_guest$\"\n",
      "features: \"^percpu_0_guest_nice$\"\n",
      "features: \"^percpu_0_idle$\"\n",
      "features: \"^percpu_0_iowait$\"\n",
      "features: \"^percpu_0_irq$\"\n",
      "features: \"^percpu_0_key$\"\n",
      "features: \"^percpu_0_nice$\"\n",
      "features: \"^percpu_0_softirq$\"\n",
      "features: \"^percpu_0_steal$\"\n",
      "features: \"^percpu_0_system$\"\n",
      "features: \"^percpu_0_total$\"\n",
      "features: \"^percpu_0_user$\"\n",
      "features: \"^processcount_running$\"\n",
      "features: \"^processcount_sleeping$\"\n",
      "features: \"^processcount_thread$\"\n",
      "features: \"^processcount_total$\"\n",
      "features: \"^system_hostname$\"\n",
      "features: \"^system_hr_name$\"\n",
      "features: \"^system_linux_distro$\"\n",
      "features: \"^system_os_name$\"\n",
      "features: \"^system_os_version$\"\n",
      "features: \"^system_platform$\"\n",
      "features: \"^timestamp$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "[INFO 24-02-13 18:31:23.2515 PST kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmp/tmpe16g9moa/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-02-13 18:31:23.2518 PST kernel.cc:887] Train model\n",
      "[INFO 24-02-13 18:31:23.2532 PST random_forest.cc:416] Training random forest on 1425 example(s) and 82 feature(s).\n",
      "[INFO 24-02-13 18:31:23.2675 PST random_forest.cc:802] Training of tree  1/300 (tree index:4) done accuracy:1 logloss:0\n",
      "[INFO 24-02-13 18:31:23.2700 PST random_forest.cc:802] Training of tree  11/300 (tree index:12) done accuracy:1 logloss:0\n",
      "[INFO 24-02-13 18:31:23.2733 PST random_forest.cc:802] Training of tree  22/300 (tree index:24) done accuracy:1 logloss:0\n",
      "[INFO 24-02-13 18:31:23.2755 PST random_forest.cc:802] Training of tree  32/300 (tree index:34) done accuracy:1 logloss:0\n",
      "[INFO 24-02-13 18:31:23.2780 PST random_forest.cc:802] Training of tree  42/300 (tree index:8) done accuracy:1 logloss:4.8416e-05\n",
      "[INFO 24-02-13 18:31:23.2803 PST random_forest.cc:802] Training of tree  52/300 (tree index:57) done accuracy:1 logloss:0.000155223\n",
      "[INFO 24-02-13 18:31:23.2846 PST random_forest.cc:802] Training of tree  65/300 (tree index:41) done accuracy:1 logloss:0.000129396\n",
      "[INFO 24-02-13 18:31:23.2893 PST random_forest.cc:802] Training of tree  75/300 (tree index:82) done accuracy:1 logloss:0.000104298\n",
      "[INFO 24-02-13 18:31:23.2915 PST random_forest.cc:802] Training of tree  85/300 (tree index:93) done accuracy:1 logloss:8.94229e-05\n",
      "[INFO 24-02-13 18:31:23.2935 PST random_forest.cc:802] Training of tree  95/300 (tree index:99) done accuracy:1 logloss:8.25465e-05\n",
      "[INFO 24-02-13 18:31:23.2965 PST random_forest.cc:802] Training of tree  105/300 (tree index:111) done accuracy:1 logloss:7.06345e-05\n",
      "[INFO 24-02-13 18:31:23.3003 PST random_forest.cc:802] Training of tree  115/300 (tree index:123) done accuracy:1 logloss:6.31384e-05\n",
      "[INFO 24-02-13 18:31:23.3029 PST random_forest.cc:802] Training of tree  125/300 (tree index:133) done accuracy:1 logloss:6.02439e-05\n",
      "[INFO 24-02-13 18:31:23.3063 PST random_forest.cc:802] Training of tree  135/300 (tree index:143) done accuracy:1 logloss:5.57312e-05\n",
      "[INFO 24-02-13 18:31:23.3090 PST random_forest.cc:802] Training of tree  145/300 (tree index:152) done accuracy:1 logloss:5.17174e-05\n",
      "[INFO 24-02-13 18:31:23.3114 PST random_forest.cc:802] Training of tree  155/300 (tree index:161) done accuracy:1 logloss:8.21716e-05\n",
      "[INFO 24-02-13 18:31:23.3175 PST random_forest.cc:802] Training of tree  165/300 (tree index:175) done accuracy:1 logloss:7.89073e-05\n",
      "[INFO 24-02-13 18:31:23.3201 PST random_forest.cc:802] Training of tree  175/300 (tree index:182) done accuracy:1 logloss:7.35314e-05\n",
      "[INFO 24-02-13 18:31:23.3239 PST random_forest.cc:802] Training of tree  185/300 (tree index:170) done accuracy:1 logloss:7.06694e-05\n",
      "[INFO 24-02-13 18:31:23.3281 PST random_forest.cc:802] Training of tree  195/300 (tree index:194) done accuracy:1 logloss:6.7036e-05\n",
      "[INFO 24-02-13 18:31:23.3321 PST random_forest.cc:802] Training of tree  206/300 (tree index:181) done accuracy:1 logloss:6.52189e-05\n",
      "[INFO 24-02-13 18:31:23.3358 PST random_forest.cc:802] Training of tree  216/300 (tree index:223) done accuracy:1 logloss:6.17423e-05\n",
      "[INFO 24-02-13 18:31:23.3403 PST random_forest.cc:802] Training of tree  226/300 (tree index:211) done accuracy:1 logloss:5.968e-05\n",
      "[INFO 24-02-13 18:31:23.3448 PST random_forest.cc:802] Training of tree  236/300 (tree index:239) done accuracy:1 logloss:5.74843e-05\n",
      "[INFO 24-02-13 18:31:23.3498 PST random_forest.cc:802] Training of tree  246/300 (tree index:232) done accuracy:1 logloss:7.89612e-05\n",
      "[INFO 24-02-13 18:31:23.3540 PST random_forest.cc:802] Training of tree  257/300 (tree index:244) done accuracy:1 logloss:7.47813e-05\n",
      "[INFO 24-02-13 18:31:23.3604 PST random_forest.cc:802] Training of tree  267/300 (tree index:274) done accuracy:1 logloss:7.05127e-05\n",
      "[INFO 24-02-13 18:31:23.3651 PST random_forest.cc:802] Training of tree  277/300 (tree index:276) done accuracy:1 logloss:6.87428e-05\n",
      "[INFO 24-02-13 18:31:23.3697 PST random_forest.cc:802] Training of tree  287/300 (tree index:267) done accuracy:1 logloss:7.2159e-05\n",
      "[INFO 24-02-13 18:31:23.3745 PST random_forest.cc:802] Training of tree  297/300 (tree index:292) done accuracy:1 logloss:7.41964e-05\n",
      "[INFO 24-02-13 18:31:23.3755 PST random_forest.cc:802] Training of tree  300/300 (tree index:294) done accuracy:1 logloss:7.28127e-05\n",
      "[INFO 24-02-13 18:31:23.3766 PST random_forest.cc:882] Final OOB metrics: accuracy:1 logloss:7.28127e-05\n",
      "[INFO 24-02-13 18:31:23.3781 PST kernel.cc:919] Export model in log directory: /tmp/tmpe16g9moa with prefix 569f49b9ef3b4059\n",
      "[INFO 24-02-13 18:31:23.3840 PST kernel.cc:937] Save model in resources\n",
      "[INFO 24-02-13 18:31:23.4024 PST abstract_model.cc:881] Model self evaluation:\n",
      "Number of predictions (without weights): 1425\n",
      "Number of predictions (with weights): 1425\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 1  CI95[W][0.9979 1]\n",
      "LogLoss: : 7.28127e-05\n",
      "ErrorRate: : 0\n",
      "\n",
      "Default Accuracy: : 0.505263\n",
      "Default LogLoss: : 0.693092\n",
      "Default ErrorRate: : 0.494737\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "     1    2\n",
      "1  720    0\n",
      "2    0  705\n",
      "Total: 1425\n",
      "\n",
      "\n",
      "[INFO 24-02-13 18:31:23.5484 PST kernel.cc:1233] Loading model from path /tmp/tmpe16g9moa/model/ with prefix 569f49b9ef3b4059\n",
      "[INFO 24-02-13 18:31:23.5546 PST decision_forest.cc:660] Model loaded with 300 root(s), 900 node(s), and 22 input feature(s).\n",
      "[INFO 24-02-13 18:31:23.5547 PST abstract_model.cc:1344] Engine \"RandomForestOptPred\" built\n",
      "[INFO 24-02-13 18:31:23.5547 PST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.332075\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ff0601bd810>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "model_1 = tfdf.keras.RandomForestModel(verbose=2)\n",
    "\n",
    "# Train the model.\n",
    "model_1.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d55f35c7-fc7e-4426-a70d-cb966340a90d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "\n",
      "loss: 0.0000\n",
      "accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(metrics=[\"accuracy\"])\n",
    "evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
    "print()\n",
    "\n",
    "for name, value in evaluation.items():\n",
    "  print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afe3316f-fd84-4ca2-b7de-a7b25527c7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nvidia_smi_log.timestamp</th>\n",
       "      <th>nvidia_smi_log.gpu.pci.tx_util</th>\n",
       "      <th>nvidia_smi_log.gpu.pci.rx_util</th>\n",
       "      <th>nvidia_smi_log.gpu.fb_memory_usage.used</th>\n",
       "      <th>nvidia_smi_log.gpu.fb_memory_usage.free</th>\n",
       "      <th>nvidia_smi_log.gpu.bar1_memory_usage.total</th>\n",
       "      <th>nvidia_smi_log.gpu.bar1_memory_usage.used</th>\n",
       "      <th>nvidia_smi_log.gpu.bar1_memory_usage.free</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.gpu_util</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.memory_util</th>\n",
       "      <th>...</th>\n",
       "      <th>nvidia_smi_log.gpu.applications_clocks.graphics_clock</th>\n",
       "      <th>nvidia_smi_log.gpu.applications_clocks.mem_clock</th>\n",
       "      <th>nvidia_smi_log.gpu.default_applications_clocks.graphics_clock</th>\n",
       "      <th>nvidia_smi_log.gpu.default_applications_clocks.mem_clock</th>\n",
       "      <th>nvidia_smi_log.gpu.max_clocks.graphics_clock</th>\n",
       "      <th>nvidia_smi_log.gpu.max_clocks.sm_clock</th>\n",
       "      <th>nvidia_smi_log.gpu.max_clocks.mem_clock</th>\n",
       "      <th>nvidia_smi_log.gpu.max_clocks.video_clock</th>\n",
       "      <th>nvidia_smi_log.gpu.max_customer_boost_clocks.graphics_clock</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Mar  3 15:03:01 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3909</td>\n",
       "      <td>12251</td>\n",
       "      <td>16384</td>\n",
       "      <td>7</td>\n",
       "      <td>16377</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1530</td>\n",
       "      <td>877</td>\n",
       "      <td>1312</td>\n",
       "      <td>877</td>\n",
       "      <td>1530</td>\n",
       "      <td>1530</td>\n",
       "      <td>877</td>\n",
       "      <td>1372</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed Mar  3 15:04:01 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>3909</td>\n",
       "      <td>12251</td>\n",
       "      <td>16384</td>\n",
       "      <td>7</td>\n",
       "      <td>16377</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1530</td>\n",
       "      <td>877</td>\n",
       "      <td>1312</td>\n",
       "      <td>877</td>\n",
       "      <td>1530</td>\n",
       "      <td>1530</td>\n",
       "      <td>877</td>\n",
       "      <td>1372</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed Mar  3 15:05:01 2021</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>3909</td>\n",
       "      <td>12251</td>\n",
       "      <td>16384</td>\n",
       "      <td>7</td>\n",
       "      <td>16377</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1530</td>\n",
       "      <td>877</td>\n",
       "      <td>1312</td>\n",
       "      <td>877</td>\n",
       "      <td>1530</td>\n",
       "      <td>1530</td>\n",
       "      <td>877</td>\n",
       "      <td>1372</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed Mar  3 15:06:01 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>3909</td>\n",
       "      <td>12251</td>\n",
       "      <td>16384</td>\n",
       "      <td>7</td>\n",
       "      <td>16377</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1530</td>\n",
       "      <td>877</td>\n",
       "      <td>1312</td>\n",
       "      <td>877</td>\n",
       "      <td>1530</td>\n",
       "      <td>1530</td>\n",
       "      <td>877</td>\n",
       "      <td>1372</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed Mar  3 15:07:01 2021</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>3909</td>\n",
       "      <td>12251</td>\n",
       "      <td>16384</td>\n",
       "      <td>7</td>\n",
       "      <td>16377</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1530</td>\n",
       "      <td>877</td>\n",
       "      <td>1312</td>\n",
       "      <td>877</td>\n",
       "      <td>1530</td>\n",
       "      <td>1530</td>\n",
       "      <td>877</td>\n",
       "      <td>1372</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nvidia_smi_log.timestamp  nvidia_smi_log.gpu.pci.tx_util  \\\n",
       "0  Wed Mar  3 15:03:01 2021                               0   \n",
       "1  Wed Mar  3 15:04:01 2021                               0   \n",
       "2  Wed Mar  3 15:05:01 2021                            1000   \n",
       "3  Wed Mar  3 15:06:01 2021                               0   \n",
       "4  Wed Mar  3 15:07:01 2021                            1000   \n",
       "\n",
       "   nvidia_smi_log.gpu.pci.rx_util  nvidia_smi_log.gpu.fb_memory_usage.used  \\\n",
       "0                               0                                     3909   \n",
       "1                            2000                                     3909   \n",
       "2                            2000                                     3909   \n",
       "3                            2000                                     3909   \n",
       "4                            2000                                     3909   \n",
       "\n",
       "   nvidia_smi_log.gpu.fb_memory_usage.free  \\\n",
       "0                                    12251   \n",
       "1                                    12251   \n",
       "2                                    12251   \n",
       "3                                    12251   \n",
       "4                                    12251   \n",
       "\n",
       "   nvidia_smi_log.gpu.bar1_memory_usage.total  \\\n",
       "0                                       16384   \n",
       "1                                       16384   \n",
       "2                                       16384   \n",
       "3                                       16384   \n",
       "4                                       16384   \n",
       "\n",
       "   nvidia_smi_log.gpu.bar1_memory_usage.used  \\\n",
       "0                                          7   \n",
       "1                                          7   \n",
       "2                                          7   \n",
       "3                                          7   \n",
       "4                                          7   \n",
       "\n",
       "   nvidia_smi_log.gpu.bar1_memory_usage.free  \\\n",
       "0                                      16377   \n",
       "1                                      16377   \n",
       "2                                      16377   \n",
       "3                                      16377   \n",
       "4                                      16377   \n",
       "\n",
       "   nvidia_smi_log.gpu.utilization.gpu_util  \\\n",
       "0                                      100   \n",
       "1                                      100   \n",
       "2                                      100   \n",
       "3                                      100   \n",
       "4                                      100   \n",
       "\n",
       "   nvidia_smi_log.gpu.utilization.memory_util  ...  \\\n",
       "0                                           2  ...   \n",
       "1                                           5  ...   \n",
       "2                                           5  ...   \n",
       "3                                           6  ...   \n",
       "4                                           6  ...   \n",
       "\n",
       "   nvidia_smi_log.gpu.applications_clocks.graphics_clock  \\\n",
       "0                                               1530       \n",
       "1                                               1530       \n",
       "2                                               1530       \n",
       "3                                               1530       \n",
       "4                                               1530       \n",
       "\n",
       "   nvidia_smi_log.gpu.applications_clocks.mem_clock  \\\n",
       "0                                               877   \n",
       "1                                               877   \n",
       "2                                               877   \n",
       "3                                               877   \n",
       "4                                               877   \n",
       "\n",
       "   nvidia_smi_log.gpu.default_applications_clocks.graphics_clock  \\\n",
       "0                                               1312               \n",
       "1                                               1312               \n",
       "2                                               1312               \n",
       "3                                               1312               \n",
       "4                                               1312               \n",
       "\n",
       "   nvidia_smi_log.gpu.default_applications_clocks.mem_clock  \\\n",
       "0                                                877          \n",
       "1                                                877          \n",
       "2                                                877          \n",
       "3                                                877          \n",
       "4                                                877          \n",
       "\n",
       "   nvidia_smi_log.gpu.max_clocks.graphics_clock  \\\n",
       "0                                          1530   \n",
       "1                                          1530   \n",
       "2                                          1530   \n",
       "3                                          1530   \n",
       "4                                          1530   \n",
       "\n",
       "   nvidia_smi_log.gpu.max_clocks.sm_clock  \\\n",
       "0                                    1530   \n",
       "1                                    1530   \n",
       "2                                    1530   \n",
       "3                                    1530   \n",
       "4                                    1530   \n",
       "\n",
       "   nvidia_smi_log.gpu.max_clocks.mem_clock  \\\n",
       "0                                      877   \n",
       "1                                      877   \n",
       "2                                      877   \n",
       "3                                      877   \n",
       "4                                      877   \n",
       "\n",
       "   nvidia_smi_log.gpu.max_clocks.video_clock  \\\n",
       "0                                       1372   \n",
       "1                                       1372   \n",
       "2                                       1372   \n",
       "3                                       1372   \n",
       "4                                       1372   \n",
       "\n",
       "   nvidia_smi_log.gpu.max_customer_boost_clocks.graphics_clock  label  \n",
       "0                                               1530                0  \n",
       "1                                               1530                0  \n",
       "2                                               1530                0  \n",
       "3                                               1530                0  \n",
       "4                                               1530                0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nvidia dataset\n",
    "\n",
    "df_train = pd.read_json(\"nvidia_train.json\")\n",
    "df_test = pd.read_csv(\"nvidia_test.csv\")\n",
    "df_train.head()print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2a7fd7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242\n"
     ]
    }
   ],
   "source": [
    "print (len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50fdff32-4474-404a-849c-3fb2c2511f41",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f5a5d56-e2f6-47bd-a74d-e1b5071ded09",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label classes: [False, True]\n",
      "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(df_train, label=\"label\")\n",
    "\n",
    "label = \"mining\"\n",
    "\n",
    "classes = df_test[label].unique().tolist()\n",
    "print(f\"Label classes: {classes}\")\n",
    "\n",
    "df_test[label] = df_test[label].map(classes.index)\n",
    "\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(df_test, label=\"mining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1976200-5b94-4620-b17a-5653bcdccdbc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 16 thread(s) for training\n",
      "Use /tmp/tmpkw1ahqkj as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'nvidia_smi_log.timestamp': <tf.Tensor 'data:0' shape=(None,) dtype=string>, 'nvidia_smi_log.gpu.pci.tx_util': <tf.Tensor 'data_1:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.pci.rx_util': <tf.Tensor 'data_2:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.fb_memory_usage.used': <tf.Tensor 'data_3:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.fb_memory_usage.free': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.bar1_memory_usage.total': <tf.Tensor 'data_5:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.bar1_memory_usage.used': <tf.Tensor 'data_6:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.bar1_memory_usage.free': <tf.Tensor 'data_7:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.utilization.gpu_util': <tf.Tensor 'data_8:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.utilization.memory_util': <tf.Tensor 'data_9:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.temperature.gpu_temp': <tf.Tensor 'data_10:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.temperature.gpu_temp_max_threshold': <tf.Tensor 'data_11:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.temperature.gpu_temp_slow_threshold': <tf.Tensor 'data_12:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.temperature.gpu_temp_max_gpu_threshold': <tf.Tensor 'data_13:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.temperature.memory_temp': <tf.Tensor 'data_14:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.temperature.gpu_temp_max_mem_threshold': <tf.Tensor 'data_15:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.power_readings.power_draw': <tf.Tensor 'data_16:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.clocks.graphics_clock': <tf.Tensor 'data_17:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.clocks.sm_clock': <tf.Tensor 'data_18:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.clocks.mem_clock': <tf.Tensor 'data_19:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.clocks.video_clock': <tf.Tensor 'data_20:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.applications_clocks.graphics_clock': <tf.Tensor 'data_21:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.applications_clocks.mem_clock': <tf.Tensor 'data_22:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.default_applications_clocks.graphics_clock': <tf.Tensor 'data_23:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.default_applications_clocks.mem_clock': <tf.Tensor 'data_24:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.max_clocks.graphics_clock': <tf.Tensor 'data_25:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.max_clocks.sm_clock': <tf.Tensor 'data_26:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.max_clocks.mem_clock': <tf.Tensor 'data_27:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.max_clocks.video_clock': <tf.Tensor 'data_28:0' shape=(None,) dtype=int64>, 'nvidia_smi_log.gpu.max_customer_boost_clocks.graphics_clock': <tf.Tensor 'data_29:0' shape=(None,) dtype=int64>}\n",
      "Label: Tensor(\"data_30:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'nvidia_smi_log.timestamp': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data:0' shape=(None,) dtype=string>), 'nvidia_smi_log.gpu.pci.tx_util': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.pci.rx_util': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.fb_memory_usage.used': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.fb_memory_usage.free': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.bar1_memory_usage.total': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.bar1_memory_usage.used': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.bar1_memory_usage.free': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_6:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.utilization.gpu_util': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_7:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.utilization.memory_util': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_8:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.temperature.gpu_temp': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_9:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.temperature.gpu_temp_max_threshold': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_10:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.temperature.gpu_temp_slow_threshold': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_11:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.temperature.gpu_temp_max_gpu_threshold': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_12:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.temperature.memory_temp': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_13:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.temperature.gpu_temp_max_mem_threshold': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_14:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.power_readings.power_draw': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_15:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.clocks.graphics_clock': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_16:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.clocks.sm_clock': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_17:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.clocks.mem_clock': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_18:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.clocks.video_clock': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_19:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.applications_clocks.graphics_clock': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_20:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.applications_clocks.mem_clock': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_21:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.default_applications_clocks.graphics_clock': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_22:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.default_applications_clocks.mem_clock': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_23:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.max_clocks.graphics_clock': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_24:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.max_clocks.sm_clock': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_25:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.max_clocks.mem_clock': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_26:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.max_clocks.video_clock': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_27:0' shape=(None,) dtype=float32>), 'nvidia_smi_log.gpu.max_customer_boost_clocks.graphics_clock': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_28:0' shape=(None,) dtype=float32>)}\n",
      "Training dataset read in 0:00:00.388350. Found 1242 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-02-13 18:32:02.2663 PST kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-02-13 18:32:02.2664 PST kernel.cc:772] Collect training examples\n",
      "[INFO 24-02-13 18:32:02.2664 PST kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-02-13 18:32:02.2665 PST kernel.cc:391] Number of batches: 2\n",
      "[INFO 24-02-13 18:32:02.2666 PST kernel.cc:392] Number of examples: 1242\n",
      "[INFO 24-02-13 18:32:02.2675 PST data_spec_inference.cc:305] 1242 item(s) have been pruned (i.e. they are considered out of dictionary) for the column nvidia_smi_log.timestamp (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "[INFO 24-02-13 18:32:02.2680 PST kernel.cc:792] Training dataset:\n",
      "Number of records: 1242\n",
      "Number of columns: 31\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 29 (93.5484%)\n",
      "\tCATEGORICAL: 2 (6.45161%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 29 (93.5484%)\n",
      "\t1: \"nvidia_smi_log.gpu.applications_clocks.graphics_clock\" NUMERICAL mean:1530 min:1530 max:1530 sd:0\n",
      "\t2: \"nvidia_smi_log.gpu.applications_clocks.mem_clock\" NUMERICAL mean:877 min:877 max:877 sd:0\n",
      "\t3: \"nvidia_smi_log.gpu.bar1_memory_usage.free\" NUMERICAL mean:16377.7 min:16373 max:16382 sd:2.80992\n",
      "\t4: \"nvidia_smi_log.gpu.bar1_memory_usage.total\" NUMERICAL mean:16384 min:16384 max:16384 sd:0\n",
      "\t5: \"nvidia_smi_log.gpu.bar1_memory_usage.used\" NUMERICAL mean:6.2971 min:2 max:11 sd:2.91028\n",
      "\t6: \"nvidia_smi_log.gpu.clocks.graphics_clock\" NUMERICAL mean:890.781 min:135 max:1350 sd:453.744\n",
      "\t7: \"nvidia_smi_log.gpu.clocks.mem_clock\" NUMERICAL mean:877 min:877 max:877 sd:0\n",
      "\t8: \"nvidia_smi_log.gpu.clocks.sm_clock\" NUMERICAL mean:890.794 min:135 max:1350 sd:453.754\n",
      "\t9: \"nvidia_smi_log.gpu.clocks.video_clock\" NUMERICAL mean:914.855 min:555 max:1215 sd:220.732\n",
      "\t10: \"nvidia_smi_log.gpu.default_applications_clocks.graphics_clock\" NUMERICAL mean:1312 min:1312 max:1312 sd:0\n",
      "\t11: \"nvidia_smi_log.gpu.default_applications_clocks.mem_clock\" NUMERICAL mean:877 min:877 max:877 sd:0\n",
      "\t12: \"nvidia_smi_log.gpu.fb_memory_usage.free\" NUMERICAL mean:12147.9 min:8896 max:16160 sd:2752.3\n",
      "\t13: \"nvidia_smi_log.gpu.fb_memory_usage.used\" NUMERICAL mean:4012.14 min:0 max:7264 sd:2752.29\n",
      "\t14: \"nvidia_smi_log.gpu.max_clocks.graphics_clock\" NUMERICAL mean:1530 min:1530 max:1530 sd:0\n",
      "\t15: \"nvidia_smi_log.gpu.max_clocks.mem_clock\" NUMERICAL mean:877 min:877 max:877 sd:0\n",
      "\t16: \"nvidia_smi_log.gpu.max_clocks.sm_clock\" NUMERICAL mean:1530 min:1530 max:1530 sd:0\n",
      "\t17: \"nvidia_smi_log.gpu.max_clocks.video_clock\" NUMERICAL mean:1372 min:1372 max:1372 sd:0\n",
      "\t18: \"nvidia_smi_log.gpu.max_customer_boost_clocks.graphics_clock\" NUMERICAL mean:1530 min:1530 max:1530 sd:0\n",
      "\t19: \"nvidia_smi_log.gpu.pci.rx_util\" NUMERICAL mean:19714.2 min:0 max:495000 sd:37700.2\n",
      "\t20: \"nvidia_smi_log.gpu.pci.tx_util\" NUMERICAL mean:11470.2 min:0 max:271000 sd:25402.3\n",
      "\t21: \"nvidia_smi_log.gpu.power_readings.power_draw\" NUMERICAL mean:114.295 min:23 max:200 sd:55.1419\n",
      "\t22: \"nvidia_smi_log.gpu.temperature.gpu_temp\" NUMERICAL mean:55.6111 min:33 max:74 sd:10.4938\n",
      "\t23: \"nvidia_smi_log.gpu.temperature.gpu_temp_max_gpu_threshold\" NUMERICAL mean:83 min:83 max:83 sd:0\n",
      "\t24: \"nvidia_smi_log.gpu.temperature.gpu_temp_max_mem_threshold\" NUMERICAL mean:85 min:85 max:85 sd:0\n",
      "\t25: \"nvidia_smi_log.gpu.temperature.gpu_temp_max_threshold\" NUMERICAL mean:90 min:90 max:90 sd:0\n",
      "\t26: \"nvidia_smi_log.gpu.temperature.gpu_temp_slow_threshold\" NUMERICAL mean:87 min:87 max:87 sd:0\n",
      "\t27: \"nvidia_smi_log.gpu.temperature.memory_temp\" NUMERICAL mean:52.2206 min:30 max:71 sd:10.7466\n",
      "\t28: \"nvidia_smi_log.gpu.utilization.gpu_util\" NUMERICAL mean:72.8478 min:0 max:100 sd:43.4463\n",
      "\t29: \"nvidia_smi_log.gpu.utilization.memory_util\" NUMERICAL mean:11.3132 min:0 max:42 sd:12.133\n",
      "\n",
      "CATEGORICAL: 2 (6.45161%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\t30: \"nvidia_smi_log.timestamp\" CATEGORICAL has-dict vocab-size:1 num-oods:1242 (100%)\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-02-13 18:32:02.2680 PST kernel.cc:808] Configure learner\n",
      "[INFO 24-02-13 18:32:02.2684 PST kernel.cc:822] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.applications_clocks\\\\.graphics_clock$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.applications_clocks\\\\.mem_clock$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.bar1_memory_usage\\\\.free$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.bar1_memory_usage\\\\.total$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.bar1_memory_usage\\\\.used$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.clocks\\\\.graphics_clock$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.clocks\\\\.mem_clock$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.clocks\\\\.sm_clock$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.clocks\\\\.video_clock$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.default_applications_clocks\\\\.graphics_clock$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.default_applications_clocks\\\\.mem_clock$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.fb_memory_usage\\\\.free$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.fb_memory_usage\\\\.used$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.max_clocks\\\\.graphics_clock$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.max_clocks\\\\.mem_clock$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.max_clocks\\\\.sm_clock$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.max_clocks\\\\.video_clock$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.max_customer_boost_clocks\\\\.graphics_clock$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.pci\\\\.rx_util$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.pci\\\\.tx_util$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.power_readings\\\\.power_draw$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.temperature\\\\.gpu_temp$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.temperature\\\\.gpu_temp_max_gpu_threshold$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.temperature\\\\.gpu_temp_max_mem_threshold$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.temperature\\\\.gpu_temp_max_threshold$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.temperature\\\\.gpu_temp_slow_threshold$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.temperature\\\\.memory_temp$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.utilization\\\\.gpu_util$\"\n",
      "features: \"^nvidia_smi_log\\\\.gpu\\\\.utilization\\\\.memory_util$\"\n",
      "features: \"^nvidia_smi_log\\\\.timestamp$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "[INFO 24-02-13 18:32:02.2685 PST kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmp/tmpkw1ahqkj/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-02-13 18:32:02.2686 PST kernel.cc:887] Train model\n",
      "[INFO 24-02-13 18:32:02.2691 PST random_forest.cc:416] Training random forest on 1242 example(s) and 30 feature(s).\n",
      "[INFO 24-02-13 18:32:02.2795 PST random_forest.cc:802] Training of tree  1/300 (tree index:1) done accuracy:1 logloss:0\n",
      "[INFO 24-02-13 18:32:02.2813 PST random_forest.cc:802] Training of tree  11/300 (tree index:9) done accuracy:1 logloss:0.000690237\n",
      "[INFO 24-02-13 18:32:02.2825 PST random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:1 logloss:0.000411956\n",
      "[INFO 24-02-13 18:32:02.2844 PST random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:1 logloss:0.000301686\n",
      "[INFO 24-02-13 18:32:02.2860 PST random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:1 logloss:0.00018522\n",
      "[INFO 24-02-13 18:32:02.2873 PST random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:1 logloss:0.000145661\n",
      "[INFO 24-02-13 18:32:02.2890 PST random_forest.cc:802] Training of tree  61/300 (tree index:61) done accuracy:1 logloss:0.000118606\n",
      "[INFO 24-02-13 18:32:02.2911 PST random_forest.cc:802] Training of tree  71/300 (tree index:72) done accuracy:1 logloss:9.90451e-05\n",
      "[INFO 24-02-13 18:32:02.2936 PST random_forest.cc:802] Training of tree  82/300 (tree index:85) done accuracy:1 logloss:8.26768e-05\n",
      "[INFO 24-02-13 18:32:02.2955 PST random_forest.cc:802] Training of tree  92/300 (tree index:94) done accuracy:1 logloss:7.32044e-05\n",
      "[INFO 24-02-13 18:32:02.2978 PST random_forest.cc:802] Training of tree  102/300 (tree index:104) done accuracy:1 logloss:6.25418e-05\n",
      "[INFO 24-02-13 18:32:02.2997 PST random_forest.cc:802] Training of tree  112/300 (tree index:114) done accuracy:1 logloss:7.6984e-05\n",
      "[INFO 24-02-13 18:32:02.3015 PST random_forest.cc:802] Training of tree  122/300 (tree index:109) done accuracy:1 logloss:8.4458e-05\n",
      "[INFO 24-02-13 18:32:02.3061 PST random_forest.cc:802] Training of tree  132/300 (tree index:100) done accuracy:1 logloss:7.84157e-05\n",
      "[INFO 24-02-13 18:32:02.3083 PST random_forest.cc:802] Training of tree  142/300 (tree index:122) done accuracy:1 logloss:7.36268e-05\n",
      "[INFO 24-02-13 18:32:02.3101 PST random_forest.cc:802] Training of tree  152/300 (tree index:153) done accuracy:1 logloss:6.97813e-05\n",
      "[INFO 24-02-13 18:32:02.3120 PST random_forest.cc:802] Training of tree  162/300 (tree index:160) done accuracy:1 logloss:6.57002e-05\n",
      "[INFO 24-02-13 18:32:02.3142 PST random_forest.cc:802] Training of tree  174/300 (tree index:174) done accuracy:1 logloss:6.21891e-05\n",
      "[INFO 24-02-13 18:32:02.3168 PST random_forest.cc:802] Training of tree  184/300 (tree index:185) done accuracy:1 logloss:5.90599e-05\n",
      "[INFO 24-02-13 18:32:02.3204 PST random_forest.cc:802] Training of tree  194/300 (tree index:200) done accuracy:1 logloss:5.30557e-05\n",
      "[INFO 24-02-13 18:32:02.3221 PST random_forest.cc:802] Training of tree  204/300 (tree index:209) done accuracy:1 logloss:5.07499e-05\n",
      "[INFO 24-02-13 18:32:02.3253 PST random_forest.cc:802] Training of tree  214/300 (tree index:223) done accuracy:1 logloss:4.89413e-05\n",
      "[INFO 24-02-13 18:32:02.3278 PST random_forest.cc:802] Training of tree  225/300 (tree index:213) done accuracy:1 logloss:4.75131e-05\n",
      "[INFO 24-02-13 18:32:02.3308 PST random_forest.cc:802] Training of tree  235/300 (tree index:240) done accuracy:1 logloss:4.5651e-05\n",
      "[INFO 24-02-13 18:32:02.3329 PST random_forest.cc:802] Training of tree  245/300 (tree index:248) done accuracy:1 logloss:4.33215e-05\n",
      "[INFO 24-02-13 18:32:02.3352 PST random_forest.cc:802] Training of tree  255/300 (tree index:263) done accuracy:1 logloss:5.03915e-05\n",
      "[INFO 24-02-13 18:32:02.3411 PST random_forest.cc:802] Training of tree  279/300 (tree index:279) done accuracy:1 logloss:4.76714e-05\n",
      "[INFO 24-02-13 18:32:02.3449 PST random_forest.cc:802] Training of tree  290/300 (tree index:291) done accuracy:1 logloss:4.55573e-05\n",
      "[INFO 24-02-13 18:32:02.3476 PST random_forest.cc:802] Training of tree  300/300 (tree index:289) done accuracy:1 logloss:4.41219e-05\n",
      "[INFO 24-02-13 18:32:02.3488 PST random_forest.cc:882] Final OOB metrics: accuracy:1 logloss:4.41219e-05\n",
      "[INFO 24-02-13 18:32:02.3492 PST kernel.cc:919] Export model in log directory: /tmp/tmpkw1ahqkj with prefix 022ab2be439f460c\n",
      "[INFO 24-02-13 18:32:02.3512 PST kernel.cc:937] Save model in resources\n",
      "[INFO 24-02-13 18:32:02.3590 PST abstract_model.cc:881] Model self evaluation:\n",
      "Number of predictions (without weights): 1242\n",
      "Number of predictions (with weights): 1242\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 1  CI95[W][0.997591 1]\n",
      "LogLoss: : 4.41219e-05\n",
      "ErrorRate: : 0\n",
      "\n",
      "Default Accuracy: : 0.848631\n",
      "Default LogLoss: : 0.425076\n",
      "Default ErrorRate: : 0.151369\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "      1    2\n",
      "1  1054    0\n",
      "2     0  188\n",
      "Total: 1242\n",
      "\n",
      "\n",
      "[INFO 24-02-13 18:32:02.3880 PST kernel.cc:1233] Loading model from path /tmp/tmpkw1ahqkj/model/ with prefix 022ab2be439f460c\n",
      "[INFO 24-02-13 18:32:02.3914 PST decision_forest.cc:660] Model loaded with 300 root(s), 942 node(s), and 10 input feature(s).\n",
      "[INFO 24-02-13 18:32:02.3915 PST abstract_model.cc:1344] Engine \"RandomForestOptPred\" built\n",
      "[INFO 24-02-13 18:32:02.3916 PST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.141054\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fefcd319060>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the model.\n",
    "model_1 = tfdf.keras.RandomForestModel(verbose=2)\n",
    "\n",
    "# Train the model.\n",
    "model_1.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a7722da-2c15-447c-9508-ad5bf5065861",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 0.9175\n",
      "\n",
      "loss: 0.0000\n",
      "accuracy: 0.9175\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(metrics=[\"accuracy\"])\n",
    "evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
    "print()\n",
    "\n",
    "for name, value in evaluation.items():\n",
    "  print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8b50d7a-d98b-4fed-b319-408b560a7106",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INV_MEAN_MIN_DEPTH': [(\"nvidia_smi_log.gpu.fb_memory_usage.free\" (1; #12),\n",
       "   0.574639254245946),\n",
       "  (\"nvidia_smi_log.gpu.fb_memory_usage.used\" (1; #13), 0.5622540138689329),\n",
       "  (\"nvidia_smi_log.gpu.bar1_memory_usage.free\" (1; #3), 0.5498869676788667),\n",
       "  (\"nvidia_smi_log.gpu.bar1_memory_usage.used\" (1; #5), 0.5485463521667587),\n",
       "  (\"nvidia_smi_log.gpu.clocks.graphics_clock\" (1; #6), 0.4982836895138975),\n",
       "  (\"nvidia_smi_log.gpu.clocks.sm_clock\" (1; #8), 0.49778761061947),\n",
       "  (\"nvidia_smi_log.gpu.clocks.video_clock\" (1; #9), 0.49417966176147676),\n",
       "  (\"nvidia_smi_log.gpu.utilization.memory_util\" (1; #29), 0.49328583173472274),\n",
       "  (\"nvidia_smi_log.gpu.pci.tx_util\" (1; #20), 0.492287495897605),\n",
       "  (\"nvidia_smi_log.gpu.pci.rx_util\" (1; #19), 0.49126637554585234)],\n",
       " 'NUM_AS_ROOT': [(\"nvidia_smi_log.gpu.fb_memory_usage.free\" (1; #12), 86.0),\n",
       "  (\"nvidia_smi_log.gpu.fb_memory_usage.used\" (1; #13), 76.0),\n",
       "  (\"nvidia_smi_log.gpu.bar1_memory_usage.free\" (1; #3), 65.0),\n",
       "  (\"nvidia_smi_log.gpu.bar1_memory_usage.used\" (1; #5), 61.0),\n",
       "  (\"nvidia_smi_log.gpu.clocks.graphics_clock\" (1; #6), 5.0),\n",
       "  (\"nvidia_smi_log.gpu.clocks.sm_clock\" (1; #8), 4.0),\n",
       "  (\"nvidia_smi_log.gpu.clocks.video_clock\" (1; #9), 2.0),\n",
       "  (\"nvidia_smi_log.gpu.pci.tx_util\" (1; #20), 1.0)],\n",
       " 'SUM_SCORE': [(\"nvidia_smi_log.gpu.fb_memory_usage.free\" (1; #12),\n",
       "   45819.28390485933),\n",
       "  (\"nvidia_smi_log.gpu.fb_memory_usage.used\" (1; #13), 40040.34742749762),\n",
       "  (\"nvidia_smi_log.gpu.bar1_memory_usage.free\" (1; #3), 34682.82035493851),\n",
       "  (\"nvidia_smi_log.gpu.bar1_memory_usage.used\" (1; #5), 32549.637863993645),\n",
       "  (\"nvidia_smi_log.gpu.clocks.graphics_clock\" (1; #6), 2198.4982132315636),\n",
       "  (\"nvidia_smi_log.gpu.clocks.sm_clock\" (1; #8), 1791.5812556147575),\n",
       "  (\"nvidia_smi_log.gpu.clocks.video_clock\" (1; #9), 840.7682080864906),\n",
       "  (\"nvidia_smi_log.gpu.pci.tx_util\" (1; #20), 404.9969052672386),\n",
       "  (\"nvidia_smi_log.gpu.utilization.memory_util\" (1; #29), 376.7857274033595),\n",
       "  (\"nvidia_smi_log.gpu.pci.rx_util\" (1; #19), 3.763258632272482)],\n",
       " 'NUM_NODES': [(\"nvidia_smi_log.gpu.fb_memory_usage.free\" (1; #12), 92.0),\n",
       "  (\"nvidia_smi_log.gpu.fb_memory_usage.used\" (1; #13), 79.0),\n",
       "  (\"nvidia_smi_log.gpu.bar1_memory_usage.free\" (1; #3), 66.0),\n",
       "  (\"nvidia_smi_log.gpu.bar1_memory_usage.used\" (1; #5), 66.0),\n",
       "  (\"nvidia_smi_log.gpu.clocks.graphics_clock\" (1; #6), 5.0),\n",
       "  (\"nvidia_smi_log.gpu.utilization.memory_util\" (1; #29), 5.0),\n",
       "  (\"nvidia_smi_log.gpu.clocks.sm_clock\" (1; #8), 4.0),\n",
       "  (\"nvidia_smi_log.gpu.clocks.video_clock\" (1; #9), 2.0),\n",
       "  (\"nvidia_smi_log.gpu.pci.rx_util\" (1; #19), 1.0),\n",
       "  (\"nvidia_smi_log.gpu.pci.tx_util\" (1; #20), 1.0)]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.make_inspector().variable_importances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2ddda3f-4da8-414b-a202-64bda6cde851",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpj3j165tc as temporary training directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 24-02-13 18:33:21.5291 PST gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-13 18:33:21.5291 PST gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-13 18:33:21.5291 PST gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7ff0d0942b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7ff0d0942b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.217494. Found 1242 examples.\n",
      "Reading validation dataset...\n",
      "Num validation examples: tf.Tensor(1164, shape=(), dtype=int32)\n",
      "Validation dataset read in 0:00:00.411524. Found 1164 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.201853\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-02-13 18:33:22.8326 PST kernel.cc:1233] Loading model from path /tmp/tmpj3j165tc/model/ with prefix 5aedc1285bf842c5\n",
      "[INFO 24-02-13 18:33:22.8334 PST quick_scorer_extended.cc:903] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n",
      "[INFO 24-02-13 18:33:22.8335 PST abstract_model.cc:1344] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO 24-02-13 18:33:22.8335 PST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fefcda1f370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fefcda1f370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x7fefcda1f640> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x7fefcda1f640> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x7ff0c9c9e050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x7ff0c9c9e050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.9175\n",
      "{'loss': 0.0, 'accuracy': 0.9175257682800293}\n"
     ]
    }
   ],
   "source": [
    "# using a subset of important features\n",
    "feature_1 = tfdf.keras.FeatureUsage(name=\"nvidia_smi_log.gpu.fb_memory_usage.free\")\n",
    "feature_2 = tfdf.keras.FeatureUsage(name=\"nvidia_smi_log.gpu.fb_memory_usage.used\")\n",
    "feature_3 = tfdf.keras.FeatureUsage(name=\"nvidia_smi_log.gpu.bar1_memory_usage.free\")\n",
    "feature_4 = tfdf.keras.FeatureUsage(name=\"nvidia_smi_log.gpu.bar1_memory_usage.used\")\n",
    "feature_5 = tfdf.keras.FeatureUsage(name=\"nvidia_smi_log.gpu.clocks.sm_clock\")\n",
    "feature_6 = tfdf.keras.FeatureUsage(name=\"nvidia_smi_log.gpu.pci.tx_util\")\n",
    "feature_7 = tfdf.keras.FeatureUsage(name=\"nvidia_smi_log.gpu.clocks.graphics_clock\")\n",
    "feature_8 = tfdf.keras.FeatureUsage(name=\"nvidia_smi_log.gpu.utilization.memory_util\")\n",
    "feature_9 = tfdf.keras.FeatureUsage(name=\"nvidia_smi_log.gpu.clocks.video_clock\")\n",
    "feature_10 = tfdf.keras.FeatureUsage(name=\"nvidia_smi_log.gpu.temperature.memory_temp\")\n",
    "\n",
    "\n",
    "all_features = [feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7, feature_8]\n",
    "model_2 = tfdf.keras.GradientBoostedTreesModel(\n",
    "    features=all_features, exclude_non_specified_features=True)\n",
    "\n",
    "model_2.compile(metrics=[\"accuracy\"])\n",
    "model_2.fit(train_ds, validation_data=test_ds)\n",
    "\n",
    "print(model_2.evaluate(test_ds, return_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c080b231-3135-4a2d-8091-471646f7a11b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alexa dataset \n",
    "\n",
    "alexa = pd.read_csv(\"alexa-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3fe6450b-9706-44a0-9d6a-33bc05a27f51",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset to simulate various types of DNS logs\n",
    "\n",
    "# Dataset of esisting DNS logs\n",
    "existing = pd.read_csv(\"dns-dataset - existing.csv\")\n",
    "# Dataset of bad DNS logs\n",
    "new_bad = pd.read_csv(\"dns-dataset - new-domains-bad.csv\")\n",
    "# Dataset of new domains good\n",
    "new_good = pd.read_csv(\"dns-dataset - new-domains-good.csv\")\n",
    "\n",
    "same = pd.read_csv(\"dns-dataset - same-domains.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "994ee329-8975-4569-9813-0ed615c79aa3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Check if domain is already existing in list or new domain\n",
    "def checkDomains(existing, new):\n",
    "    for index in existing.index:\n",
    "        value = existing[existing.columns[0]].iloc[index]\n",
    "        if (new.empty == True):\n",
    "            pass\n",
    "        elif (value in new['Domains '].values):\n",
    "            new = new[new['Domains '] != value]\n",
    "    new = new.reset_index()\n",
    "    return (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "408b2771-8504-406d-a4fa-ec599e6d8ae0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Check if domain exists in known alexa domain list\n",
    "def checkAlexa(new):\n",
    "    if (new.empty):\n",
    "        return True \n",
    "    else:\n",
    "        for index in new.index: \n",
    "            if (new[new.columns[1]].iloc[index] not in alexa['google.com'].values):\n",
    "                return False\n",
    "                \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b18470ca-12bd-4571-a905-752bf36063a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same domain: Domain already exists in known list\n",
      "Known domain: Domain exists in Alexa, Not in known list\n",
      "Malicious domain: Domain does not exist in Alexa or Known list\n"
     ]
    }
   ],
   "source": [
    "# Check if domain exist in known list or in Alexa list\n",
    "df = checkDomains(existing, same)\n",
    "if df.empty:\n",
    "    print (\"Same domain: Domain already exists in known list\")\n",
    "else:\n",
    "    checkAlexa(df)\n",
    " \n",
    "\n",
    "df = checkDomains(existing, new_good)\n",
    "if df.empty:\n",
    "    print (\"Domain already exists in known list\")\n",
    "else:\n",
    "    if (checkAlexa(df)  is True):\n",
    "        print (\"Known domain: Domain exists in Alexa, Not in known list\")\n",
    "    else:\n",
    "        print (\"Malicious domain: Domain does not exist in Alexa or Known list\")\n",
    "\n",
    "\n",
    "df = checkDomains(existing, new_bad)\n",
    "if (df.empty):\n",
    "    print (\"Domain already exists in known list\")\n",
    "else:\n",
    "    if (checkAlexa(df)  is True):\n",
    "        print (\"Known domain - Domain exists in Alexa\")\n",
    "    else:\n",
    "        print (\"Malicious domain: Domain does not exist in Alexa or Known list\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
